--------------> 1.Step: Audio signals processing

The aim of the project is to process audio signals using deep learning. 
In fact, its main purpose is to lay a foundation for voice recognition and classification.

See also: https://en.wikipedia.org/wiki/Audio_signal_processing

Dataset: https://urbansounddataset.weebly.com/download-urbansound8k.html

The dataset consists of 10 classes and there are 8732 data. (Audio file)

MeI-Frequency Cepstral (MFC) by processing each audio file in the project
I manipulated the algorithm using the MeI-Frequency Cepstral Coefficients
I calculated (MFCC)

Librosa, one of the most popular Python libraries, was used.
Discrete Fourier Transform (DFT)

--------------> 2.Step: Audio Classification with Deep Learning

After manipulating the audio files, I did my Deep Learning study.

The architecture has 3 hidden layers and a total of 500 neurons (125-250-125).
CNN (Convolutional Neural Network) algorithm was used.

